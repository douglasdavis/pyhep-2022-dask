{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "955586f6",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.dask.org/en/latest/_images/dask_horizontal.svg\" align=\"right\" width=\"30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02064b8d",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>\n",
    "Dask Tutorial for PyHEP 2022\n",
    "    </h1>\n",
    "</center>\n",
    "\n",
    "Dask is a pure Python library for parallel and distributed computing designed to scale up workflows in the PyData ecosystem.\n",
    "\n",
    "The two main components of Dask:\n",
    "\n",
    "- The **collections library(ies)** (sometimes called \"Dask core\") listed here in alphabetical order:\n",
    "  - `dask.array`: chunked NumPy\n",
    "  - `dask.bag`: partitioned Python iterables\n",
    "  - `dask.dataframe`: partitioned Pandas\n",
    "  - `dask.delayed`: custom algorithms\n",
    "- The **execution engines** (task schedulers)\n",
    "  - The distributed engine is its own project (`distributed`, sometimes called \"Dask Distributed\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4911fe3d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://docs.dask.org/en/stable/_images/dask-overview.svg\" align=\"center\" width=\"70%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353aed9-95b3-4f5f-ba63-3ab6e6edd55c",
   "metadata": {},
   "source": [
    "There are also a number of other projects in the Dask ecosystem that leverage both upstream components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac9a3c-fb91-46a2-b1db-4d1f28932032",
   "metadata": {},
   "source": [
    "First Example (using `dask.delayed`)\n",
    "------------------------------------\n",
    "\n",
    "We'll start with a simple `dask.delayed` example that covers _a lot_ of how Dask works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.delayed import delayed\n",
    "\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "inc = delayed(inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49504827-e768-4482-9dde-7a1232a74e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14288fe8-6993-4533-aa20-3172a52292d3",
   "metadata": {},
   "source": [
    "Notice that this just creates a `Delayed` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab375e37-28f8-43db-9e8e-f4f05bba5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "eight = inc(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60660ca-ab55-4de4-93c3-50fc3581a091",
   "metadata": {},
   "source": [
    "We have to ask Dask to determine the result via `compute()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fc2c1-4af0-4ca7-9292-2ab8865ce317",
   "metadata": {},
   "outputs": [],
   "source": [
    "eight.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32581a4-266e-4b58-b599-00824cc0ad69",
   "metadata": {},
   "source": [
    "We can start to construct a more complex task graph by chaining function calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5819f9-196d-4b61-9904-64dca6bd4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "@delayed\n",
    "def add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ac52b4-b898-46b6-9831-63a5efbcf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "five = add(inc(1), inc(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56b62e-89cd-4c2d-b66e-9a0b32974297",
   "metadata": {},
   "outputs": [],
   "source": [
    "five.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b942e764-650c-4651-a61d-d150766e95d7",
   "metadata": {},
   "source": [
    "We can inspect the complete task graph to see how dask accomplishing computing the result of the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fa2b9-4b6b-47c8-a323-062f376f504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_task_graph = five.dask.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae648d-c729-41e5-aa6d-aef534fd8db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (k, v) in enumerate(delayed_task_graph.items()):\n",
    "    if i != 0:\n",
    "        print(\"\\n\")\n",
    "    print(\"The key (label) of a task:   \", k)\n",
    "    print(\"The task itself (Lisp S-exp):\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6fe781-1b82-4172-83e4-7bdb75af785f",
   "metadata": {},
   "source": [
    "There is a much better method of inspection! (`visualize()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050846b-e0a7-47e3-bd52-bdd3998d5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "five.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff30f9-f82c-4422-90da-c27acb8976be",
   "metadata": {},
   "source": [
    "Second Example\n",
    "--------------\n",
    "\n",
    "Let's take a look at an example that illustrates something closer to a real workflow: reading and operating on files to produce a histogram. Our example will have two steps:\n",
    "\n",
    "1. Load an uproot TTree by file and tree name\n",
    "2. Calculate something from information in the file\n",
    "3. Histogram the calculation\n",
    "\n",
    "We'll look at the workflow while leveraging Dask, and compare to a workflow without Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089d84d-fa4b-4e6b-8ae9-1b5946bcd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "import hist\n",
    "import time\n",
    "from skhep_testdata import data_path\n",
    "paths = [data_path(\"uproot-Zmumu.root\")] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea99418-0bc0-4d82-ad2c-1177efd72655",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def read_tree(file_name, tree_name):\n",
    "    time.sleep(1)  # faking making the file larger\n",
    "    return uproot.open(file_name)[tree_name]\n",
    "\n",
    "@delayed\n",
    "def calculation(tree):\n",
    "    arrs = tree.arrays()\n",
    "    return abs(arrs.E1 - arrs.E2)\n",
    "    \n",
    "@delayed\n",
    "def histo(data, bins, range):\n",
    "    h = hist.Hist(hist.axis.Regular(bins=bins, start=range[0], stop=range[1], name=\"abs(E1-E2)\"))\n",
    "    h.fill(data)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993192bc-eb69-4cb6-9a97-1fcefbedd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "histos = []\n",
    "for p in paths:\n",
    "    tree = read_tree(p, \"events\")\n",
    "    calc = calculation(tree)\n",
    "    h = histo(calc, 20, (0, 200))\n",
    "    histos.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b78483-2e25-4bb3-8786-748fc1d587f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "histos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78732b6c-4fb1-4f6f-8c9b-8a136f863e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(histos).visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35962701-6ef3-4eb3-84d7-a80b839c694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(histos).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13467d3-7526-4bea-9b39-783a43cdf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sum(histos).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c778f80-3ff1-4271-8841-ee68f303ede7",
   "metadata": {},
   "source": [
    "Now without Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe157a2-746f-4da1-b130-00b1509eba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_read_tree(file_name, tree_name):\n",
    "    time.sleep(1)  # faking making the file larger\n",
    "    return uproot.open(file_name)[tree_name]\n",
    "\n",
    "def s_calculation(tree):\n",
    "    arrs = tree.arrays()\n",
    "    return abs(arrs.E1 - arrs.E2)\n",
    "    \n",
    "def s_histo(data, bins, range):\n",
    "    h = hist.Hist(hist.axis.Regular(bins=bins, start=range[0], stop=range[1], name=\"abs(E1-E2)\"))\n",
    "    h.fill(data)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5799c62-961a-40a2-a3a7-de05e06aad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "s_histos = []\n",
    "for p in paths:\n",
    "    tree = s_read_tree(p, \"events\")\n",
    "    calc = s_calculation(tree)\n",
    "    h = histo(calc, 20, (0, 200))\n",
    "    s_histos.append(h)\n",
    "sum(s_histos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe7ff9c-2482-413e-9022-37d8ab08e797",
   "metadata": {},
   "source": [
    "dask.array\n",
    "=========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5d651-1301-4ed5-8eb6-913a1e8a936d",
   "metadata": {},
   "source": [
    "While `dask.delayed` is incredibly flexible and can turn almost any Python function into a node in a task graph, the other collection libraries are designed to provide task graph creation as a near drop in replacement to existing PyData libraries. The NumPy API is meant to be recreated with `dask.array`. Arrays in `dask.array` are chunked and lazily evaluated NumPy arrays. The data nodes in a task graph are just NumPy arrays: Dask doesn't create a new array computation kernel library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540970af-9a0b-4abb-bcba-f1c0743f1546",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://docs.dask.org/en/stable/_images/dask-array.svg\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00ba32-ea2a-49f9-8070-cf2c5e660513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e4275-57ee-4404-b0eb-7205ca8da22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.ones((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f3cbb-4f16-48ab-a2f7-c6c723b2b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415275df-293a-4e76-b4ea-4a53e2bedbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1[:5].sum() + a1[5:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05715e67-f41d-400e-af86-1aa119f68fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = da.ones((10,), chunks=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d094fb5-ab19-4c41-945a-d6e2fce87c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15795bb5-0f26-4141-9531-cc4f2305774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a28840-7d84-4283-9a11-344c81e74d5d",
   "metadata": {},
   "source": [
    "Chaining together function calls with `dask.array` is very similar to what we did with `dask.delayed`: it simply builds up the task graph. However, now we get to use the ubiquitous NumPy API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e762fc-f411-4432-9ac7-b77c3e1dadc7",
   "metadata": {},
   "source": [
    "dask.dataframe\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5840fec-f327-48f0-89ab-e65f432c395a",
   "metadata": {},
   "source": [
    "The NumPy/dask.array relationship is mirrored for Pandas with dask.dataframe. DataFrames(Series) in dask.dataframe are partitioned and lazily evalualated Pandas DataFrames(Series). The data nodes in a task graph are pandas objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fbf1c2-08ad-431a-a51c-0775730b6b0b",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://docs.dask.org/en/stable/_images/dask-dataframe.svg\" width=\"35%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf86758-c204-4c75-9acb-0f236c1b2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.datasets import timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f29b4-4931-4288-b897-63f3a1500ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4f534-e33f-4d3d-b516-58f486f8a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e2474-41f0-4b4a-9c67-281d7ab0e65e",
   "metadata": {},
   "source": [
    "distributed\n",
    "==========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0587960-7ffd-4604-8601-8f8d8d1dfe96",
   "metadata": {},
   "source": [
    "So far in this tutorial we've been using the default execution engine at each `.compute()` call. This has been the threaded scheduler: Dask tried to use all threads on the system where you have imported Dask. This parallelizes computation on a laptop, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a89ac-1ca9-4176-9e53-50efdd90cfc7",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"images/distributed.png\" width=60%\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
